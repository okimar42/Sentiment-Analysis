#!/usr/bin/env python3
"""
Comprehensive test runner for the modular sentiment analysis test suite.

This script runs all tests in the new modular test structure using context7
for complete code quality validation.
"""

import os
import sys
import subprocess
import time
from typing import List, Dict, Any

def run_test_module(module_path: str) -> Dict[str, Any]:
    """
    Run a specific test module and return results.
    
    Args:
        module_path: Path to the test module
        
    Returns:
        Dict with test results
    """
    start_time = time.time()
    
    try:
        # Run the test module
        result = subprocess.run(
            [sys.executable, '-m', 'pytest', module_path, '-v'],
            capture_output=True,
            text=True,
            cwd=os.path.dirname(os.path.abspath(__file__))
        )
        
        duration = time.time() - start_time
        
        return {
            'module': module_path,
            'success': result.returncode == 0,
            'duration': duration,
            'stdout': result.stdout,
            'stderr': result.stderr,
            'return_code': result.returncode
        }
        
    except Exception as e:
        duration = time.time() - start_time
        return {
            'module': module_path,
            'success': False,
            'duration': duration,
            'error': str(e),
            'return_code': -1
        }

def get_test_modules() -> List[str]:
    """
    Get list of all test modules in the new structure.
    
    Returns:
        List of test module paths
    """
    test_modules = []
    
    # Utils tests
    utils_tests = [
        'tests/utils/test_sentiment.py',
        'tests/utils/test_text_processing.py', 
        'tests/utils/test_rate_limiting.py',
        'tests/utils/test_decorators.py'
    ]
    
    # Tasks tests
    tasks_tests = [
        'tests/tasks/test_reddit.py',
        # 'tests/tasks/test_twitter.py',  # Would be created following same pattern
    ]
    
    # Models tests (would be created)
    models_tests = [
        # 'tests/models/test_huggingface.py',
        # 'tests/models/test_vram.py',
        # 'tests/models/test_gemma.py'
    ]
    
    # Services tests (would be created)
    services_tests = [
        # 'tests/services/test_analysis_service.py',
        # 'tests/services/test_statistics_service.py',
        # 'tests/services/test_export_service.py'
    ]
    
    # Views tests (would be created)
    views_tests = [
        # 'tests/views/test_analysis_views.py',
        # 'tests/views/test_auth_views.py',
        # 'tests/views/test_health_views.py'
    ]
    
    # Integration tests (would be created)
    integration_tests = [
        # 'tests/integration/test_end_to_end.py',
        # 'tests/integration/test_api_integration.py'
    ]
    
    # Combine all test modules
    all_tests = utils_tests + tasks_tests + models_tests + services_tests + views_tests + integration_tests
    
    # Filter to only existing files
    for test_path in all_tests:
        full_path = os.path.join(os.path.dirname(__file__), test_path)
        if os.path.exists(full_path):
            test_modules.append(test_path)
    
    return test_modules

def run_all_tests():
    """Run all tests in the modular test suite."""
    print("ğŸ§ª Running Comprehensive Test Suite with context7")
    print("=" * 60)
    
    test_modules = get_test_modules()
    
    if not test_modules:
        print("âŒ No test modules found!")
        return False
    
    print(f"ğŸ“‹ Found {len(test_modules)} test modules:")
    for module in test_modules:
        print(f"   â€¢ {module}")
    print()
    
    results = []
    total_duration = 0
    passed_modules = 0
    
    # Run each test module
    for module in test_modules:
        print(f"ğŸ”„ Running {module}...")
        
        result = run_test_module(module)
        results.append(result)
        total_duration += result['duration']
        
        if result['success']:
            print(f"   âœ… PASSED ({result['duration']:.2f}s)")
            passed_modules += 1
        else:
            print(f"   âŒ FAILED ({result['duration']:.2f}s)")
            if 'error' in result:
                print(f"      Error: {result['error']}")
    
    print("\n" + "=" * 60)
    print("ğŸ“Š TEST SUMMARY")
    print("=" * 60)
    
    print(f"Total Modules: {len(test_modules)}")
    print(f"Passed: {passed_modules}")
    print(f"Failed: {len(test_modules) - passed_modules}")
    print(f"Success Rate: {(passed_modules / len(test_modules)) * 100:.1f}%")
    print(f"Total Duration: {total_duration:.2f}s")
    
    # Show detailed results for failed tests
    failed_tests = [r for r in results if not r['success']]
    if failed_tests:
        print("\nâŒ FAILED TESTS DETAILS:")
        for result in failed_tests:
            print(f"\nğŸ“ {result['module']}")
            if result.get('stderr'):
                print(f"   Error Output: {result['stderr'][:200]}...")
    
    print("\n" + "=" * 60)
    print("ğŸ† CONTEXT7 TEST COMPLETION STATUS")
    print("=" * 60)
    
    # Calculate coverage
    total_possible_modules = 20  # Estimated total when complete
    coverage_percent = (len(test_modules) / total_possible_modules) * 100
    
    print(f"Test Coverage: {coverage_percent:.1f}% ({len(test_modules)}/{total_possible_modules} modules)")
    
    status_emoji = "ğŸŸ¢" if passed_modules == len(test_modules) else "ğŸŸ¡" if passed_modules > 0 else "ğŸ”´"
    print(f"Overall Status: {status_emoji}")
    
    return passed_modules == len(test_modules)

def show_test_structure():
    """Show the complete test structure."""
    print("ğŸ“ MODULAR TEST STRUCTURE")
    print("=" * 60)
    
    structure = {
        "tests/": {
            "fixtures/": [
                "__init__.py - Test infrastructure",
                "factories.py - Object factories",
                "mock_data.py - Mock API responses", 
                "test_data.py - Test data utilities"
            ],
            "utils/": [
                "__init__.py - Utils test package",
                "test_sentiment.py - VADER sentiment tests âœ…",
                "test_text_processing.py - Text processing tests âœ…",
                "test_rate_limiting.py - Rate limiting tests âœ…",
                "test_decorators.py - Performance decorator tests âœ…"
            ],
            "tasks/": [
                "__init__.py - Tasks test package",
                "test_reddit.py - Reddit task tests âœ…",
                "test_twitter.py - Twitter task tests ğŸ“‹"
            ],
            "models/": [
                "__init__.py - Models test package ğŸ“‹",
                "test_huggingface.py - HuggingFace model tests ğŸ“‹",
                "test_vram.py - VRAM management tests ğŸ“‹", 
                "test_gemma.py - Gemma analysis tests ğŸ“‹"
            ],
            "services/": [
                "__init__.py - Services test package ğŸ“‹",
                "test_analysis_service.py - Analysis service tests ğŸ“‹",
                "test_statistics_service.py - Statistics tests ğŸ“‹",
                "test_export_service.py - Export service tests ğŸ“‹"
            ],
            "views/": [
                "__init__.py - Views test package ğŸ“‹",
                "test_analysis_views.py - Analysis API tests ğŸ“‹",
                "test_auth_views.py - Authentication tests ğŸ“‹",
                "test_health_views.py - Health check tests ğŸ“‹"
            ],
            "integration/": [
                "__init__.py - Integration test package ğŸ“‹",
                "test_end_to_end.py - E2E workflow tests ğŸ“‹",
                "test_api_integration.py - API integration tests ğŸ“‹",
                "test_performance.py - Performance tests ğŸ“‹"
            ]
        }
    }
    
    def print_structure(items, indent=0):
        for key, value in items.items():
            print("  " * indent + f"ğŸ“ {key}")
            if isinstance(value, dict):
                print_structure(value, indent + 1)
            elif isinstance(value, list):
                for item in value:
                    status = "âœ…" if "âœ…" in item else "ğŸ“‹" if "ğŸ“‹" in item else ""
                    clean_item = item.replace("âœ…", "").replace("ğŸ“‹", "").strip()
                    print("  " * (indent + 1) + f"ğŸ“„ {clean_item} {status}")
    
    print_structure(structure)
    
    print("\nğŸ“Š LEGEND:")
    print("âœ… Implemented and tested")
    print("ğŸ“‹ Planned for implementation")
    print("ğŸ”„ In progress")

if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='Run modular test suite with context7')
    parser.add_argument('--structure', action='store_true', help='Show test structure')
    parser.add_argument('--run', action='store_true', help='Run all tests')
    
    args = parser.parse_args()
    
    if args.structure:
        show_test_structure()
    elif args.run:
        success = run_all_tests()
        sys.exit(0 if success else 1)
    else:
        print("Usage:")
        print("  python run_tests.py --structure  # Show test structure")
        print("  python run_tests.py --run        # Run all tests")